# ---- llm ----
model: GPTAPI
temperature: null
top_p: null

# ---- behaviour ----
stream: true # Controls whether to use the stream-style API.
save: true # Indicates whether to persist the message
keybindings: emacs # Choose keybinding style (emacs, vi)
editor: null # Specifies the command used to edit input buffer or session. (e.g. vim, emacs, nano).
wrap: no # Controls text wrapping (no, auto, <max-width>)
wrap_code: false # Enables or disables wrapping of code blocks

# ---- prelude ----
prelude: null # Set a default role or session to start with (e.g. role:<name>, session:<name>)
repl_prelude: null # Overrides the `prelude` setting specifically for conversations started in REPL
agent_prelude: null # Set a session to use when starting a agent. (e.g. temp, default)

# ---- session ----
# Controls the persistence of the session. if true, auto save; if false, not save; if null, asking the user
save_session: null
# Compress session when token count reaches or exceeds this threshold
compress_threshold: 4000
# Text prompt used for creating a concise summary of session message
summarize_prompt: "Summarize the discussion briefly in 200 words or less to use as a prompt for future context."
# Text prompt used for including the summary of the entire session
summary_prompt: "This is a summary of the chat history as a recap: "

# # ---- RAG ----
# # See [RAG-Guide](https://github.com/sigoden/aichat/wiki/RAG-Guide) for more details.
# rag_embedding_model: null                   # Specifies the embedding model to use
# rag_reranker_model: null                    # Specifies the rerank model to use
# rag_top_k: 4                                # Specifies the number of documents to retrieve
# rag_chunk_size: null                        # Specifies the chunk size
# rag_chunk_overlap: null                     # Specifies the chunk overlap
# rag_min_score_vector_search: 0              # Specifies the minimum relevance score for vector-based searching
# rag_min_score_keyword_search: 0             # Specifies the minimum relevance score for keyword-based searching
# rag_min_score_rerank: 0                     # Specifies the minimum relevance score for reranking
# # Defines the query structure using variables like __CONTEXT__ and __INPUT__ to tailor searches to specific needs
# rag_template: |
#   Use the following context as your learned knowledge, inside <context></context> XML tags.
#   <context>
#   __CONTEXT__
#   </context>
#
#   When answer to user:
#   - If you don't know, just say that you don't know.
#   - If you don't know when you are not sure, ask for clarification.
#   Avoid mentioning that you obtained the information from the context.
#   And answer according to the language of the user's question.
#
#   Given the context information, answer the query.
#   Query: __INPUT__
# # Define document loaders to control how RAG and `.file`/`--file` load files of specific formats.
# document_loaders:
#   # You can add custom loaders using the following syntax:
#   #   <file-extension>: <command-to-load-the-file>
#   # Note: Use `$1` for input file and `$2` for output file. If `$2` is omitted, use stdout as output.
#   pdf: 'pdftotext $1 -'                         # Load .pdf file, see https://poppler.freedesktop.org to set up pdftotext
#   docx: 'pandoc --to plain $1'                  # Load .docx file, see https://pandoc.org to set up pandoc
clients:
  - type: openai-compatible
    name: GPTAPI
    api_base: https://api.gptapi.us/v1/chat/completions
    api_key: sk-LoRwMK0dPaFM0Ji43b775912Be904c09893308Ff1eFeCc77
    models:
      - name: claude-3-5-sonnet
        max_input_tokens: 128000
  - type: openai-compatible
    name: o1
    api_base: https://api.gptapi.us/v1/chat/completions
    api_key: sk-LoRwMK0dPaFM0Ji43b775912Be904c09893308Ff1eFeCc77
    models:
      - name: o1-mini
        max_input_tokens: 128000
